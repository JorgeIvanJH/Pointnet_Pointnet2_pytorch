{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Datasets\\ModelNet\\ModelNet10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import datetime\n",
    "import logging\n",
    "import provider\n",
    "import importlib\n",
    "import shutil\n",
    "import argparse\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "# from data_utils.ModelNetDataLoader import ModelNetDataLoader\n",
    "\n",
    "DATASET_DIR = os.getenv('DATASET_DIR')\n",
    "print(DATASET_DIR)\n",
    "# BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "# ROOT_DIR = BASE_DIR\n",
    "# sys.path.append(os.path.join(ROOT_DIR, 'models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Names for Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: D:/Datasets/ModelNet/ModelNet10\\modelnet10_train.txt\n",
      "✅ Saved: D:/Datasets/ModelNet/ModelNet10\\modelnet10_test.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATASET_DIR = \"D:/Datasets/ModelNet/ModelNet10\"\n",
    "for split in [\"train\", \"test\"]:\n",
    "    OUTPUT_FILE = os.path.join(DATASET_DIR, f\"modelnet10_{split}.txt\")\n",
    "\n",
    "    with open(OUTPUT_FILE, 'w') as f_out:\n",
    "        for class_dir in sorted(os.listdir(DATASET_DIR)):\n",
    "            class_path = os.path.join(DATASET_DIR, class_dir, split)\n",
    "            if os.path.isdir(class_path):\n",
    "                for file in os.listdir(class_path):\n",
    "                    if file.endswith('.off') or file.endswith('.txt'):\n",
    "                        file_id = os.path.splitext(file)[0]\n",
    "                        f_out.write(f\"{file_id}\\n\")\n",
    "\n",
    "    print(f\"✅ Saved: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating .txt point samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = 1024\n",
    "\n",
    "# Function to convert .off to .txt (point cloud)\n",
    "def sample_off_to_txt(file_path, dest_path, num_points=1024):\n",
    "    try:\n",
    "        mesh = trimesh.load(file_path)\n",
    "        if not mesh.is_watertight:\n",
    "            mesh = mesh.convex_hull\n",
    "\n",
    "        points, _ = trimesh.sample.sample_surface(mesh, num_points)\n",
    "        np.savetxt(dest_path, points, fmt='%.6f', delimiter=',')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Process both train and test splits\n",
    "for split in [\"train\", \"test\"]:\n",
    "    output_txt = os.path.join(DATASET_DIR, f\"modelnet10_{split}.txt\")\n",
    "\n",
    "    with open(output_txt, 'w') as f_out:\n",
    "        for class_dir in sorted(os.listdir(DATASET_DIR)):\n",
    "            class_path = os.path.join(DATASET_DIR, class_dir, split)\n",
    "            if os.path.isdir(class_path):\n",
    "                for file in sorted(os.listdir(class_path)):\n",
    "                    if file.endswith('.off'):\n",
    "                        file_id = os.path.splitext(file)[0]\n",
    "                        off_path = os.path.join(class_path, file)\n",
    "                        txt_path = os.path.join(class_path, file_id + '.txt')\n",
    "\n",
    "                        # Convert if .txt does not exist\n",
    "                        if not os.path.exists(txt_path):\n",
    "                            success = sample_off_to_txt(off_path, txt_path, NUM_POINTS)\n",
    "                            if not success:\n",
    "                                continue  # skip writing to the file list if conversion failed\n",
    "\n",
    "                        # Add entry to split list\n",
    "                        f_out.write(f\"{file_id}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
